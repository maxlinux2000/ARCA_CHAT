# ARCA_CHAT: Tu Bibliotecario IA Offline üìöü§ñ

**ARCA_CHAT** es una soluci√≥n de inteligencia artificial dise√±ada para actuar como un bibliotecario personal, privado y resiliente. A diferencia de los modelos de chat comerciales, reside completamente en tu hardware, permiti√©ndote **dialogar directamente con tus propios documentos, libros y archivos** sin que un solo bit de informaci√≥n salga de tu equipo.

El proyecto nace de la necesidad de rescatar, organizar y consultar el conocimiento digital personal en un entorno de soberan√≠a tecnol√≥gica absoluta.

---

## üåü El Coraz√≥n del Proyecto: Di√°logo con la Biblioteca

El prop√≥sito principal de ARCA_CHAT es establecer un puente interactivo con tu propia base de conocimiento (la Biblioteca del Arca):

* **Interacci√≥n con Libros (RAG):** Puedes preguntarle a ARCA sobre conceptos espec√≠ficos tratados en vol√∫menes extensos y recibir respuestas basadas exclusivamente en esos textos.
* **An√°lisis de Documentaci√≥n:** Ideal para revisar manuales t√©cnicos, documentos hist√≥ricos o colecciones personales de manera conversacional.
* **Soberan√≠a y Privacidad:** El "bibliotecario" trabaja a puerta cerrada. Todo el procesamiento es local, garantizando que el acceso al conocimiento no dependa de servidores externos ni de pol√≠ticas de terceros.

---

## ‚öôÔ∏è ¬øC√≥mo funciona?

ARCA_CHAT utiliza una arquitectura de **Generaci√≥n Aumentada por Recuperaci√≥n** (RAG), combinando la potencia de procesamiento de lenguaje natural con una gesti√≥n de memoria local eficiente.

El proceso se divide en tres etapas:

1.  **Ingesta y Fragmentaci√≥n:** El sistema procesa tus archivos (PDF, Markdown, Texto plano, etc.) y los divide en fragmentos manejables.
2.  **Indexaci√≥n (La Memoria del Arca):** Estos fragmentos se convierten en representaciones num√©ricas (*embeddings*) almacenadas en una base de datos vectorial local. Esto permite a la IA localizar informaci√≥n relevante en segundos.
3.  **Consulta y Respuesta:** Al realizar una pregunta, el sistema busca los fragmentos m√°s pertinentes en tu biblioteca y se los entrega al modelo de lenguaje local (`llama.cpp`) para generar una respuesta fundamentada √∫nicamente en tus documentos.

Conceptos Avanzados: Atomic-Search y Destilaci√≥n con Doble IA

La arquitectura de la Biblioteca del Arca implementa el concepto de Atomic-Search, un m√©todo de recuperaci√≥n que descompone las consultas complejas en unidades m√≠nimas de significado para garantizar que la IA localice el dato exacto, incluso en documentos de miles de p√°ginas donde la sem√°ntica puede ser ambigua. Este proceso se potencia mediante una destilaci√≥n con doble modelo de IA: un primer modelo "Maestro" de gran escala (ej. Llama 70b) se utiliza en una fase previa fuera de l√≠nea para etiquetar y destilar el conocimiento cr√≠tico de tu biblioteca hacia un modelo "Estudiante" m√°s compacto y eficiente (ej. Mistral o Qwen 8b). Este flujo de doble modelo permite que el "Estudiante", que es el que reside f√≠sicamente en tu hardware local, mantenga una precisi√≥n t√©cnica excepcional y una l√≥gica de razonamiento superior sin necesidad de los recursos masivos del modelo original, eliminando alucinaciones y optimizando la velocidad de respuesta en el escenario offline del Arca.


---

## üõ†Ô∏è Tecnolog√≠as Clave

Para asegurar el funcionamiento en hardware dom√©stico y sistemas aislados (Debian 12 / Raspberry Pi), ARCA_CHAT se apoya en:

* **ollama:** El motor principal para ejecutar modelos de lenguaje potentes con alta eficiencia.
* **Memvid:** Integraci√≥n para la gesti√≥n inteligente del contexto y la memoria de largo plazo de los documentos.
* **Instalaci√≥n Offline:** Uso de scripts para empaquetar dependencias y modelos, permitiendo el despliegue del sistema sin necesidad de conexi√≥n a internet.

---

> [!IMPORTANT]
> **Estado del proyecto:** ARCA_CHAT se encuentra actualmente "en altamar". El desarrollo est√° en fase activa de arquitectura y dise√±o de la base de datos vectorial. Los scripts de despliegue final se a√±adir√°n una vez consolidada la estructura del "Bibliotecario".
